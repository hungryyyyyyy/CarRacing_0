{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7447d1e2",
   "metadata": {},
   "source": [
    "### library and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73680287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library and functions\n",
    "import argparse\n",
    "import gym\n",
    "from collections import deque\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# common_functions\n",
    "def process_state_image(state):\n",
    "    state = cv2.cvtColor(state, cv2.COLOR_BGR2GRAY)\n",
    "    state = state.astype(float)\n",
    "    state /= 255.0\n",
    "    return state\n",
    "\n",
    "def generate_state_frame_stack_from_queue(deque):\n",
    "    frame_stack = np.array(deque)\n",
    "    # Move stack dimension to the channel dimension (stack, x, y) -> (x, y, stack)\n",
    "    return np.transpose(frame_stack, (1, 2, 0))\n",
    "\n",
    "# CarRacingDQNAgent\n",
    "import random\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class CarRacingDQNAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        action_space    = [\n",
    "            (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2), #           Action Space Structure\n",
    "            (-1, 1,   0), (0, 1,   0), (1, 1,   0), #        (Steering Wheel, Gas, Break)\n",
    "            (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2), # Range        -1~1       0~1   0~1\n",
    "            (-1, 0,   0), (0, 0,   0), (1, 0,   0)\n",
    "        ],\n",
    "        frame_stack_num = 3,\n",
    "        memory_size     = 5000,\n",
    "        gamma           = 0.95,  # discount rate\n",
    "        epsilon         = 1.0,   # exploration rate\n",
    "        epsilon_min     = 0.1,\n",
    "        epsilon_decay   = 0.9999,\n",
    "        learning_rate   = 0.001\n",
    "    ):\n",
    "        self.action_space    = action_space\n",
    "        self.frame_stack_num = frame_stack_num\n",
    "        self.memory          = deque(maxlen=memory_size)\n",
    "        self.gamma           = gamma\n",
    "        self.epsilon         = epsilon\n",
    "        self.epsilon_min     = epsilon_min\n",
    "        self.epsilon_decay   = epsilon_decay\n",
    "        self.learning_rate   = learning_rate\n",
    "        self.model           = self.build_model()\n",
    "        self.target_model    = self.build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=6, kernel_size=(7, 7), strides=3, activation='relu', input_shape=(96, 96, self.frame_stack_num)))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(filters=12, kernel_size=(4, 4), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(216, activation='relu'))\n",
    "        model.add(Dense(len(self.action_space), activation=None))\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam(lr=self.learning_rate, epsilon=1e-7))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, self.action_space.index(action), reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() > self.epsilon:\n",
    "            act_values = self.model.predict(np.expand_dims(state, axis=0))\n",
    "            action_index = np.argmax(act_values[0])\n",
    "        else:\n",
    "            action_index = random.randrange(len(self.action_space))\n",
    "        return self.action_space[action_index]\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        train_state = []\n",
    "        train_target = []\n",
    "        for state, action_index, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(np.expand_dims(state, axis=0))[0]\n",
    "            if done:\n",
    "                target[action_index] = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(np.expand_dims(next_state, axis=0))[0]\n",
    "                target[action_index] = reward + self.gamma * np.amax(t)\n",
    "            train_state.append(state)\n",
    "            train_target.append(target)\n",
    "        self.model.fit(np.array(train_state), np.array(train_target), epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "        self.update_target_model()\n",
    "\n",
    "    def save(self, name):\n",
    "        self.target_model.save_weights(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f301fc",
   "metadata": {},
   "source": [
    "### train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f4bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model\n",
    "RENDER                        = True\n",
    "STARTING_EPISODE              = 1\n",
    "ENDING_EPISODE                = 1000\n",
    "SKIP_FRAMES                   = 2\n",
    "TRAINING_BATCH_SIZE           = 64\n",
    "SAVE_TRAINING_FREQUENCY       = 25\n",
    "UPDATE_TARGET_MODEL_FREQUENCY = 5\n",
    "\n",
    "\n",
    "def train_model(args):\n",
    "    \n",
    "    env = gym.make('CarRacing-v0')\n",
    "    agent = CarRacingDQNAgent(epsilon=args['epsilon'])\n",
    "    if args['model']:\n",
    "        agent.load(args['model'])\n",
    "    if args['start']:\n",
    "        STARTING_EPISODE = args['start']\n",
    "    if args['end']:\n",
    "        ENDING_EPISODE = args['end']\n",
    "\n",
    "    for e in range(STARTING_EPISODE, ENDING_EPISODE+1):\n",
    "        init_state = env.reset()\n",
    "        init_state = process_state_image(init_state)\n",
    "\n",
    "        total_reward = 0\n",
    "        negative_reward_counter = 0\n",
    "        state_frame_stack_queue = deque([init_state]*agent.frame_stack_num, maxlen=agent.frame_stack_num)\n",
    "        time_frame_counter = 1\n",
    "        done = False\n",
    "        \n",
    "        while True:\n",
    "            if RENDER:\n",
    "                env.render()\n",
    "\n",
    "            current_state_frame_stack = generate_state_frame_stack_from_queue(state_frame_stack_queue)\n",
    "            action = agent.act(current_state_frame_stack)\n",
    "\n",
    "            reward = 0\n",
    "            for _ in range(SKIP_FRAMES+1):\n",
    "                next_state, r, done, info = env.step(action)\n",
    "                reward += r\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            # If continually getting negative reward 10 times after the tolerance steps, terminate this episode\n",
    "            negative_reward_counter = negative_reward_counter + 1 if time_frame_counter > 100 and reward < 0 else 0\n",
    "\n",
    "            # Extra bonus for the model if it uses full gas\n",
    "            if action[1] == 1 and action[2] == 0:\n",
    "                reward *= 1.5\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "            next_state = process_state_image(next_state)\n",
    "            state_frame_stack_queue.append(next_state)\n",
    "            next_state_frame_stack = generate_state_frame_stack_from_queue(state_frame_stack_queue)\n",
    "\n",
    "            agent.memorize(current_state_frame_stack, action, reward, next_state_frame_stack, done)\n",
    "\n",
    "            if done or negative_reward_counter >= 25 or total_reward < 0:\n",
    "                print('Episode: {}/{}, Scores(Time Frames): {}, Total Rewards(adjusted): {:.2}, Epsilon: {:.2}'.format(e, ENDING_EPISODE, time_frame_counter, float(total_reward), float(agent.epsilon)))\n",
    "                break\n",
    "            if len(agent.memory) > TRAINING_BATCH_SIZE:\n",
    "                agent.replay(TRAINING_BATCH_SIZE)\n",
    "            time_frame_counter += 1\n",
    "\n",
    "        if e % UPDATE_TARGET_MODEL_FREQUENCY == 0:\n",
    "            agent.update_target_model()\n",
    "\n",
    "        if e % SAVE_TRAINING_FREQUENCY == 0:\n",
    "            agent.save('./save/trial_{}.h5'.format(e))\n",
    "\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d4066",
   "metadata": {},
   "source": [
    "### test training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab4700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "args = {}\n",
    "args['model']='save/trial_100.h5' # 'Specify the last trained model path if you want to continue training after it.'\n",
    "args['start']=1 # 'The starting episode, default to 1.'\n",
    "args['end']=1000 # 'The ending episode, default to 1000.'\n",
    "args['epsilon']=1.0 # 'The starting epsilon of the agent, default to 1.0.'\n",
    "args['episodes']=1 # 'The number of episodes should the model plays.'\n",
    "\n",
    "# Train the Deep Q Network(DQN)\n",
    "#train_model(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb20905",
   "metadata": {},
   "source": [
    "### play_car_racing_with_keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92429c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_car_racing_with_keyboard\n",
    "is_pressed_left  = False # control left\n",
    "is_pressed_right = False # control right\n",
    "is_pressed_space = False # control gas\n",
    "is_pressed_shift = False # control break\n",
    "is_pressed_esc   = False # exit the game\n",
    "steering_wheel = 0 # init to 0\n",
    "gas            = 0 # init to 0\n",
    "break_system   = 0 # init to 0\n",
    "\n",
    "def key_press(key, mod):\n",
    "    global is_pressed_left\n",
    "    global is_pressed_right\n",
    "    global is_pressed_space\n",
    "    global is_pressed_shift\n",
    "    global is_pressed_esc\n",
    "\n",
    "    if key == 65361:\n",
    "        is_pressed_left = True\n",
    "    if key == 65363:\n",
    "        is_pressed_right = True\n",
    "    if key == 32:\n",
    "        is_pressed_space = True\n",
    "    if key == 65505:\n",
    "        is_pressed_shift = True\n",
    "    if key == 65307:\n",
    "        is_pressed_esc = True\n",
    "\n",
    "def key_release(key, mod):\n",
    "    global is_pressed_left\n",
    "    global is_pressed_right\n",
    "    global is_pressed_space\n",
    "    global is_pressed_shift\n",
    "\n",
    "    if key == 65361:\n",
    "        is_pressed_left = False\n",
    "    if key == 65363:\n",
    "        is_pressed_right = False\n",
    "    if key == 32:\n",
    "        is_pressed_space = False\n",
    "    if key == 65505:\n",
    "        is_pressed_shift = False\n",
    "\n",
    "def update_action():\n",
    "    global steering_wheel\n",
    "    global gas\n",
    "    global break_system\n",
    "\n",
    "    if is_pressed_left ^ is_pressed_right:\n",
    "        if is_pressed_left:\n",
    "            if steering_wheel > -1:\n",
    "                steering_wheel -= 0.1\n",
    "            else:\n",
    "                steering_wheel = -1\n",
    "        if is_pressed_right:\n",
    "            if steering_wheel < 1:\n",
    "                steering_wheel += 0.1\n",
    "            else:\n",
    "                steering_wheel = 1\n",
    "    else:\n",
    "        if abs(steering_wheel - 0) < 0.1:\n",
    "            steering_wheel = 0\n",
    "        elif steering_wheel > 0:\n",
    "            steering_wheel -= 0.1\n",
    "        elif steering_wheel < 0:\n",
    "            steering_wheel += 0.1\n",
    "    if is_pressed_space:\n",
    "        if gas < 1:\n",
    "            gas += 0.1\n",
    "        else:\n",
    "            gas = 1\n",
    "    else:\n",
    "        if gas > 0:\n",
    "            gas -= 0.1\n",
    "        else:\n",
    "            gas = 0\n",
    "    if is_pressed_shift:\n",
    "        if break_system < 1:\n",
    "            break_system += 0.1\n",
    "        else:\n",
    "            break_system = 1\n",
    "    else:\n",
    "        if break_system > 0:\n",
    "            break_system -= 0.1\n",
    "        else:\n",
    "            break_system = 0\n",
    "\n",
    "def play_car_racing_with_keyboard():\n",
    "    env = gym.make('CarRacing-v1')\n",
    "    state = env.reset()\n",
    "    env.unwrapped.viewer.window.on_key_press = key_press\n",
    "    env.unwrapped.viewer.window.on_key_release = key_release\n",
    "\n",
    "    counter = 0\n",
    "    total_reward = 0\n",
    "    while not is_pressed_esc:\n",
    "        env.render()\n",
    "        update_action()\n",
    "        action = [steering_wheel, gas, break_system]\n",
    "        state, reward, done, info = env.step(action)\n",
    "        counter += 1\n",
    "        total_reward += reward\n",
    "        print('Action:[{:+.1f}, {:+.1f}, {:+.1f}] Reward: {:.3f}'.format(action[0], action[1], action[2], reward))\n",
    "        if done:\n",
    "            print(\"Restart game after {} timesteps. Total Reward: {}\".format(counter, total_reward))\n",
    "            counter = 0\n",
    "            total_reward = 0\n",
    "            state = env.reset()\n",
    "            continue\n",
    "\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b51e5",
   "metadata": {},
   "source": [
    "### test the play\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d829c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#play_car_racing_with_keyboard(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13281924",
   "metadata": {},
   "source": [
    "### play_car_racing_by_the_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f3b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_car_racing_by_the_model(args):\n",
    "    train_model = args['model']\n",
    "    play_episodes = args['episodes']\n",
    "\n",
    "    env = gym.make('CarRacing-v0')\n",
    "    agent = CarRacingDQNAgent(epsilon=0) # Set epsilon to 0 to ensure all actions are instructed by the agent\n",
    "    agent.load(train_model)\n",
    "\n",
    "    for e in range(play_episodes):\n",
    "        init_state = env.reset()\n",
    "        init_state = process_state_image(init_state)\n",
    "\n",
    "        total_reward = 0\n",
    "        punishment_counter = 0\n",
    "        state_frame_stack_queue = deque([init_state]*agent.frame_stack_num, maxlen=agent.frame_stack_num)\n",
    "        time_frame_counter = 1\n",
    "        \n",
    "        while True:\n",
    "            env.render()\n",
    "\n",
    "            current_state_frame_stack = generate_state_frame_stack_from_queue(state_frame_stack_queue)\n",
    "            action = agent.act(current_state_frame_stack)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "            next_state = process_state_image(next_state)\n",
    "            state_frame_stack_queue.append(next_state)\n",
    "\n",
    "            if done:\n",
    "                print('Episode: {}/{}, Scores(Time Frames): {}, Total Rewards: {:.2}'.format(e+1, play_episodes, time_frame_counter, float(total_reward)))\n",
    "                break\n",
    "            time_frame_counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b42e8",
   "metadata": {},
   "source": [
    "### test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5b91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#play_car_racing_by_the_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915498a",
   "metadata": {},
   "source": [
    "### display the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c38e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 400\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './resources/trial_400.gif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH 400\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./resources/trial_400.gif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './resources/trial_400.gif'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "print('EPOCH 400')\n",
    "Image(filename=\"./resources/trial_400.gif\",width=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23135ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EPOCH 500')\n",
    "Image(filename=\"./resources/trial_500.gif\",width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d414d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EPOCH 600')\n",
    "Image(filename=\"./resources/trial_600.gif\",width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031f26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ae38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
